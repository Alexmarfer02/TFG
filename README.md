# Dise√±o de Sistemas de Evaluaci√≥n de las Capacidades de Clasificaci√≥n de los Grandes Modelos de Lenguaje y Comparacion con otros modelos de Procesamiento de Lenguaje Natural

**Autor**: √Ålex M√°rquez Fern√°ndez de la Vega  
**Grado**: Ingenier√≠a de Tecnolog√≠as y Servicios de Telecomunicaci√≥n  
**Universidad**: UPM - ETSI de Telecomunicaci√≥n  
**Fecha**: Junio 2025

---

## Descripci√≥n

Este repositorio contiene el c√≥digo, scripts y recursos utilizados en el Trabajo de Fin de Grado enfocado en el an√°lisis y evaluaci√≥n de la capacidad de los Grandes Modelos del Lenguaje (LLMs) para realizar tareas de clasificaci√≥n de sentimiento en espa√±ol. Se comparan modelos generalistas (GPT-4o, LLaMA, Gemma) con un modelo especializado (RoBERTuito), utilizando t√©cnicas como prompting (zero-shot, few-shot y Chain-of-Thought) y fine-tuning supervisado.

---

## Objetivos del Proyecto

- Comparar modelos generalistas y especializados en an√°lisis de sentimiento en espa√±ol.
- Evaluar estrategias de prompting y su impacto en la clasificaci√≥n.
- Realizar fine-tuning sobre GPT-4o-mini y analizar su rendimiento.
- Estudiar la coherencia interna de los razonamientos generados (CoT).
- Utilizar m√©tricas est√°ndar (accuracy, precision, recall, F1-score) y an√°lisis sem√°ntico (PCA, clustering).

---

## Estructura del Repositorio

- `Clasificar_Polaridad/`: scripts y notebooks para ejecutar los modelos y clasificar los datasets.
  - `Generalistas/`: notebooks para GPT-4o, LLaMA, Gemma.
    - `fine-tuning/`: scripts, datos y resultados del fine-tuning sobre GPT-4o-mini.
  - `GPT-4o-mini/`: notebooks y prompts para evaluar con distintos esquemas de prompting.
  - `Robertuito/`: notebook de evaluaci√≥n con el modelo especializado RoBERTuito.
- `DataSets/`: datasets originales InterTASS 2019 y 2020 y scripts de procesamiento.
- `Resultados/`: notebooks de an√°lisis y visualizaci√≥n.
  - `analisis fine-tuning/`: m√©tricas y comparativas tras fine-tuning.
  - `analisis prompts/`: an√°lisis de prompting y razonamiento CoT.

---

## Tecnolog√≠as y Herramientas

- **Lenguaje:** Python
- **Librer√≠as:** pandas, scikit-learn, matplotlib, seaborn, spaCy, transformers, openai, pysentimiento
- **APIs**: [OpenAI](https://platform.openai.com/), [Groq](https://console.groq.com/)
- **Modelos evaluados:**
  - Generalistas: GPT-4o (OpenAI), LLaMA (Groq), Gemma (Groq)
  - Especializado: RoBERTuito (Hugging Face)
- **Entornos**: Jupyter Notebook
- **T√©cnicas:** prompting (zero-shot, few-shot, CoT), fine-tuning supervisado, BoW, TF-IDF, PCA, clustering

---
Para ejecutar este proyecto en tu m√°quina local, sigue estos pasos:

bash
Copiar
Editar
# 1. Clona el repositorio
git clone https://github.com/Alexmarfer02/TFG.git
cd TFG

# 2. Instala las dependencias (Python 3.10+ recomendado)
pip install -r requirements.txt
‚ñ∂Ô∏è C√≥mo ejecutar los experimentos
A continuaci√≥n se indican los notebooks principales para cada fase del proyecto:

üîç Clasificaci√≥n de polaridad
GPT-4o (OpenAI):
Clasificar_Polaridad/GPT-4o-mini/Extraer_GPT-4o-mini.ipynb

Modelos generalistas (Groq):

Clasificar_Polaridad/Generalistas/Clasificar_gemma2-9b-it.ipynb

Clasificar_Polaridad/Generalistas/Clasificar_llama-3.1-8b-instant.ipynb

Clasificar_Polaridad/Generalistas/Clasificar_llama-3.3-70b-versatile.ipynb

Modelo especializado (RoBERTuito):
Clasificar_Polaridad/Robertuito/Clasificar_Robertuito.ipynb

üõ†Ô∏è Fine-tuning de GPT-4o-mini
Scripts y datasets:

Clasificar_Polaridad/Generalistas/fine-tuning/entrenamiento/Fine-Tuning_Dataset2019.py

Clasificar_Polaridad/Generalistas/fine-tuning/entrenamiento/Fine-Tuning_Dataset2019&2020.py

Evaluaci√≥n de modelos fine-tuned:

Clasificar_Polaridad/Generalistas/fine-tuning/Extraer_GPT-4o-mini&FineTuning.ipynb

üìä An√°lisis y visualizaci√≥n de resultados
Comparativas de rendimiento:

Resultados/analisis fine-tuning/graficas-comparativas.ipynb

An√°lisis de prompting:

Resultados/analisis prompts/analisis_prompts.ipynb

Resultados/analisis prompts/graficas-prompts.ipynb

An√°lisis de razonamiento (CoT):

Resultados/analisis prompts/An√°lisis de razonamiento/Razonamientos_GPT-4o-mini.ipynb

Resultados/analisis prompts/An√°lisis de razonamiento/Razonamientos_llama-3.3-70b-versatile.ipynb

‚ö†Ô∏è Requisitos externos
Cuenta en OpenAI con clave API para usar GPT-4o-mini.

Cuenta en Groq Cloud para ejecutar LLaMA y Gemma.

Claves API deben configurarse en los notebooks o scripts correspondientes.





